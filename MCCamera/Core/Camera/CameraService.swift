import AVFoundation
import UIKit
import Photos
import CoreLocation

class CameraService: NSObject, ObservableObject {
    let session = AVCaptureSession()
    private var videoOutput = AVCaptureVideoDataOutput()
    private var photoOutput = AVCapturePhotoOutput()
    var currentDevice: AVCaptureDevice?
    private var currentInput: AVCaptureDeviceInput?
    
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    
    // Manager instances
    private let locationManager = LocationManager()
    private lazy var highResolutionManager = HighResolutionCameraManager(
        sessionQueue: sessionQueue,
        photoOutput: photoOutput
    )
    private lazy var photoProcessor = PhotoProcessor(locationManager: locationManager)
    private lazy var photoSettingsManager = PhotoSettingsManager(photoOutput: photoOutput)
    
    var previewLayer: AVCaptureVideoPreviewLayer {
        let layer = AVCaptureVideoPreviewLayer(session: session)
        layer.videoGravity = .resizeAspectFill
        return layer
    }
    
    var availableCameras: [AVCaptureDevice] = []
    var currentCameraIndex: Int = 0
    
    // æ·»åŠ è®¾ç½®ç›¸å…³çš„å±æ€§
    private var currentPhotoFormat: PhotoFormat = .heic
    private var currentPhotoResolution: PhotoResolution = .resolution12MP
    
    private var photoCompletionHandler: ((Result<Data, Error>) -> Void)?
    private var currentAspectRatio: AspectRatio?
    private var currentFrameSettings: FrameSettings?
    
    override init() {
        super.init()
        // ç«‹å³è¿›è¡Œå¿«é€Ÿåˆå§‹åŒ–
        quickSetup()
    }
    
    private func quickSetup() {
        print("ğŸš€ å¼€å§‹å¿«é€Ÿè®¾ç½®ç›¸æœº")
        // æ‰€æœ‰ç›¸æœºè®¾ç½®ç§»åˆ°åå°çº¿ç¨‹ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            print("ğŸ¥ åå°é…ç½®ç›¸æœº...")
            // ä½¿ç”¨é»˜è®¤åç½®ç›¸æœºè¿›è¡Œå¿«é€Ÿè®¾ç½®
            guard let defaultCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
                print("âŒ æ— æ³•è·å–é»˜è®¤ç›¸æœº")
                return
            }
            
            self.session.beginConfiguration()
            
            // è®¾ç½®session preset - å¯¹äº48MPæ•è·å¾ˆé‡è¦
            self.configureSessionPreset()
            
            // é…ç½®é»˜è®¤ç›¸æœº
            self.configureDefaultCamera(defaultCamera)
            
            // æ·»åŠ è¾“å‡ºå¹¶é…ç½®é«˜åˆ†è¾¨ç‡æ•è·
            self.configurePhotoOutput()
            
            self.session.commitConfiguration()
            
            // éªŒè¯é…ç½®çŠ¶æ€
            self.verifyConfiguration()
            
            // æ›´æ–°ç›¸æœºåˆ—è¡¨ï¼ˆåœ¨ä¸»çº¿ç¨‹ï¼‰
            DispatchQueue.main.async {
                self.availableCameras = [defaultCamera]
                print("âœ… å¿«é€Ÿè®¾ç½®å®Œæˆï¼Œç›¸æœºå¯ç”¨")
            }
            
            // å‘ç°å…¶ä»–ç›¸æœº
            self.discoverAdditionalCameras()
        }
    }
    
    private func configureSessionPreset() {
        let presets: [AVCaptureSession.Preset] = [.photo, .high, .inputPriority]
        var presetSet = false
        
        for preset in presets {
            if self.session.canSetSessionPreset(preset) {
                self.session.sessionPreset = preset
                print("ğŸš€ å¿«é€Ÿè®¾ç½®: Session presetè®¾ç½®ä¸º \(preset.rawValue)")
                presetSet = true
                break
            }
        }
        
        if !presetSet {
            print("âŒ å¿«é€Ÿè®¾ç½®: æ— æ³•è®¾ç½®ä»»ä½•é¦–é€‰preset")
        }
    }
    
    private func configureDefaultCamera(_ defaultCamera: AVCaptureDevice) {
        do {
            let input = try AVCaptureDeviceInput(device: defaultCamera)
            if self.session.canAddInput(input) {
                self.session.addInput(input)
                self.currentInput = input
                self.currentDevice = defaultCamera
            }
        } catch {
            print("âŒ é…ç½®é»˜è®¤ç›¸æœºå¤±è´¥: \(error)")
        }
    }
    
    private func configurePhotoOutput() {
        if self.session.canAddOutput(self.photoOutput) {
            self.session.addOutput(self.photoOutput)
            
            // ç«‹å³å¯ç”¨é«˜åˆ†è¾¨ç‡æ•è·
            self.photoOutput.isHighResolutionCaptureEnabled = true
            print("ğŸš€ å¿«é€Ÿè®¾ç½®: é«˜åˆ†è¾¨ç‡æ•è·å·²å¯ç”¨")
            
            // è®¾ç½®æœ€é«˜è´¨é‡ä¼˜å…ˆçº§
            self.photoOutput.maxPhotoQualityPrioritization = .quality
            
            print("ğŸš€ å¿«é€Ÿè®¾ç½®PhotoOutputçŠ¶æ€:")
            print("  - é«˜åˆ†è¾¨ç‡æ•è·å¯ç”¨: \(self.photoOutput.isHighResolutionCaptureEnabled)")
        } else {
            print("âŒ å¿«é€Ÿè®¾ç½®: æ— æ³•æ·»åŠ photoOutput")
        }
    }
    
    private func verifyConfiguration() {
        print("ğŸš€ Sessioné…ç½®å®Œæˆåï¼ŒPhotoOutputæœ€ç»ˆçŠ¶æ€:")
        print("  - é«˜åˆ†è¾¨ç‡æ•è·å¯ç”¨: \(self.photoOutput.isHighResolutionCaptureEnabled)")
        print("  - å¯ç”¨ç¼–è§£ç å™¨ç±»å‹: \(self.photoOutput.availablePhotoCodecTypes)")
        
        // å¦‚æœåˆå§‹åˆ†è¾¨ç‡è®¾ç½®ä¸º48MPï¼Œç¡®ä¿é…ç½®48MPæ¨¡å¼
        if self.currentPhotoResolution == .resolution48MP {
            print("ğŸš€ å¿«é€Ÿè®¾ç½®: æ£€æµ‹åˆ°48MPåˆå§‹è®¾ç½®ï¼Œé…ç½®48MPæ¨¡å¼")
            if let device = currentDevice {
                self.highResolutionManager.configureFor48MP(enable: true, device: device, session: session)
            }
        }
    }
    
    private func discoverAdditionalCameras() {
        let cameraDiscovery = CameraDiscovery()
        let newCameras = cameraDiscovery.discoverCameras()
        
        // æ›´æ–°ç›¸æœºåˆ—è¡¨
        DispatchQueue.main.async { [weak self] in
            self?.availableCameras = newCameras.isEmpty ? (self?.availableCameras ?? []) : newCameras
            print("å‘ç°çš„ç›¸æœºæ•°é‡: \(self?.availableCameras.count ?? 0)")
            
            // å¦‚æœæœ‰å¤šä¸ªç›¸æœºï¼Œé»˜è®¤åˆ‡æ¢åˆ°1xé•œå¤´ï¼ˆç´¢å¼•ä¸º1ï¼‰
            if let self = self, self.availableCameras.count > 1 {
                self.switchCamera(to: 1)
            }
        }
    }
    
    func requestPermissions(completion: @escaping (Bool) -> Void) {
        let cameraAuthStatus = AVCaptureDevice.authorizationStatus(for: .video)
        
        switch cameraAuthStatus {
        case .authorized:
            completion(true)
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                DispatchQueue.main.async {
                    completion(granted)
                }
            }
        default:
            completion(false)
        }
    }
    
    func startSession() {
        sessionQueue.async { [weak self] in
            guard let self = self, !self.session.isRunning else { return }
            
            self.session.startRunning()
            print("âœ… Sessionå·²å¯åŠ¨")
        }
    }
    
    func stopSession() {
        sessionQueue.async { [weak self] in
            guard let self = self, self.session.isRunning else { return }
            self.session.stopRunning()
        }
    }
    
    func switchCamera(to index: Int) {
        guard index >= 0 && index < availableCameras.count else { return }
        
        let selectedCamera = availableCameras[index]
        currentCameraIndex = index
        
        print("ğŸ”„ åˆ‡æ¢ç›¸æœºåˆ°ç´¢å¼• \(index)")
        print("ğŸ”„ é€‰ä¸­çš„ç›¸æœº: \(selectedCamera.localizedName) (\(selectedCamera.deviceType.rawValue))")
        
        configureCamera(selectedCamera)
    }
    
    private func configureCamera(_ device: AVCaptureDevice) {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            self.session.beginConfiguration()
            
            if let currentInput = self.currentInput {
                self.session.removeInput(currentInput)
            }
            
            do {
                let input = try AVCaptureDeviceInput(device: device)
                if self.session.canAddInput(input) {
                    self.session.addInput(input)
                    self.currentInput = input
                    self.currentDevice = device
                    
                    // é‡æ–°é…ç½®PhotoOutputä»¥ç¡®ä¿é«˜åˆ†è¾¨ç‡æ•è·æ­£ç¡®è®¾ç½®
                    self.photoOutput.isHighResolutionCaptureEnabled = true
                    print("ğŸ“· è®¾å¤‡åˆ‡æ¢å: é«˜åˆ†è¾¨ç‡æ•è·é‡æ–°å¯ç”¨")
                    
                    // ä¸º48MPé…ç½®è®¾å¤‡æ ¼å¼
                    if self.currentPhotoResolution == .resolution48MP {
                        self.highResolutionManager.configureFor48MP(enable: true, device: device, session: self.session)
                    }
                }
            } catch {
                print("Error configuring camera: \(error)")
            }
            
            self.session.commitConfiguration()
        }
    }
    
    func capturePhoto(aspectRatio: AspectRatio? = nil, flashMode: AVCaptureDevice.FlashMode = .auto, frameSettings: FrameSettings? = nil, completion: @escaping (Result<Data, Error>) -> Void) {
        sessionQueue.async { [weak self] in
            guard let self = self else { return }
            
            // æ£€æŸ¥ session æ˜¯å¦åœ¨è¿è¡Œ
            guard self.session.isRunning else {
                DispatchQueue.main.async {
                    completion(.failure(NSError(domain: "CameraService", code: -1, userInfo: [NSLocalizedDescriptionKey: "ç›¸æœºæœªå¯åŠ¨"])))
                }
                return
            }
            
            // åˆ›å»ºç…§ç‰‡è®¾ç½®
            let settings = self.photoSettingsManager.createPhotoSettings(
                format: self.currentPhotoFormat,
                resolution: self.currentPhotoResolution
            )
            
            // è®¾ç½®é—ªå…‰ç¯æ¨¡å¼
            if let currentDevice = self.currentDevice, currentDevice.hasFlash {
                settings.flashMode = flashMode
                print("ğŸ“¸ è®¾ç½®é—ªå…‰ç¯æ¨¡å¼ä¸º: \(flashMode.rawValue)")
            } else {
                settings.flashMode = .off
                print("ğŸ“¸ è®¾å¤‡ä¸æ”¯æŒé—ªå…‰ç¯ï¼Œè®¾ç½®ä¸ºå…³é—­")
            }
            
            // ä½¿ç”¨è®¾å¤‡æ”¯æŒçš„æœ€é«˜è´¨é‡è®¾ç½®
            let maxQuality = self.photoOutput.maxPhotoQualityPrioritization
            if maxQuality.rawValue >= AVCapturePhotoOutput.QualityPrioritization.quality.rawValue {
                settings.photoQualityPrioritization = .quality
            } else if maxQuality.rawValue >= AVCapturePhotoOutput.QualityPrioritization.balanced.rawValue {
                settings.photoQualityPrioritization = .balanced
            } else {
                settings.photoQualityPrioritization = .speed
            }
            
            // Appleå»ºè®®ï¼šå¯ç”¨åµŒå…¥å¼ç¼©ç•¥å›¾ä»¥è·å¾—æ›´å¥½çš„ç›¸å†Œä½“éªŒ
            if settings.availableEmbeddedThumbnailPhotoCodecTypes.contains(.jpeg) {
                settings.embeddedThumbnailPhotoFormat = [
                    AVVideoCodecKey: AVVideoCodecType.jpeg
                ]
            }
            
            // è®¾ç½®æ–¹å‘ä¿¡æ¯
            if let connection = self.photoOutput.connection(with: .video) {
                if connection.isVideoOrientationSupported {
                    connection.videoOrientation = .portrait
                }
            }
            
            print("ğŸ“¸ æ‹ç…§è®¾ç½®é…ç½®å®Œæˆ")
            
            self.photoCompletionHandler = completion
            self.currentAspectRatio = aspectRatio
            
            // ä¿å­˜ç›¸æ¡†è®¾ç½®ï¼Œç”¨äºåç»­å¤„ç†
            self.currentFrameSettings = frameSettings
            
            self.photoOutput.capturePhoto(with: settings, delegate: self)
        }
    }
    
    func setFocusPoint(_ point: CGPoint) {
        guard let device = currentDevice, device.isFocusPointOfInterestSupported else { return }
        
        do {
            try device.lockForConfiguration()
            device.focusPointOfInterest = point
            device.focusMode = .autoFocus
            
            if device.isExposurePointOfInterestSupported {
                device.exposurePointOfInterest = point
                device.exposureMode = .autoExpose
            }
            
            device.unlockForConfiguration()
        } catch {
            print("Error setting focus point: \(error)")
        }
    }
    
    func setExposureCompensation(_ value: Float) {
        guard let device = currentDevice else { return }
        
        do {
            try device.lockForConfiguration()
            
            // ç¡®ä¿è®¾å¤‡å¤„äºè¿ç»­è‡ªåŠ¨æ›å…‰æ¨¡å¼ï¼Œä»¥ä¾¿æ›å…‰è¡¥å¿ç”Ÿæ•ˆ
            if device.isExposureModeSupported(.continuousAutoExposure) {
                device.exposureMode = .continuousAutoExposure
            }
            
            // é™åˆ¶æ›å…‰è¡¥å¿å€¼åœ¨è®¾å¤‡æ”¯æŒçš„èŒƒå›´å†…
            let clampedValue = max(device.minExposureTargetBias, min(value, device.maxExposureTargetBias))
            device.setExposureTargetBias(clampedValue, completionHandler: { time in
                print("ğŸ“¸ CameraService: æ›å…‰è¡¥å¿è®¾ç½®å®Œæˆ - å€¼: \(clampedValue), æ—¶é—´: \(time.seconds)ç§’")
            })
            
            device.unlockForConfiguration()
        } catch {
            print("Error setting exposure compensation: \(error)")
        }
    }
    
    // æ›´æ–°è®¾ç½®çš„æ–¹æ³•
    func updatePhotoSettings(format: PhotoFormat, resolution: PhotoResolution) {
        let needsSessionReconfiguration = (currentPhotoResolution != resolution)
        
        currentPhotoFormat = format
        currentPhotoResolution = resolution
        print("ğŸ“¸ æ›´æ–°ç…§ç‰‡è®¾ç½® - æ ¼å¼: \(format.rawValue), åˆ†è¾¨ç‡: \(resolution.rawValue)")
        
        // å¦‚æœåˆ†è¾¨ç‡æ”¹å˜ï¼Œéœ€è¦é‡æ–°é…ç½®session
        if needsSessionReconfiguration {
            sessionQueue.async { [weak self] in
                self?.reconfigureSession()
            }
        }
    }
    
    // é‡æ–°é…ç½®sessionçš„æ–¹æ³•
    private func reconfigureSession() {
        guard session.isRunning else { return }
        
        print("ğŸ”„ é‡æ–°é…ç½®Session - åˆ†è¾¨ç‡: \(currentPhotoResolution.rawValue)")
        
        session.beginConfiguration()
        
        // æ ¹æ®æ–°çš„åˆ†è¾¨ç‡è®¾ç½®session preset
        let sessionPreset = CameraHelper.getSessionPreset(for: currentPhotoResolution, session: session)
        if session.canSetSessionPreset(sessionPreset) {
            session.sessionPreset = sessionPreset
            print("ğŸ“¸ æ›´æ–°session presetä¸º: \(sessionPreset.rawValue)")
        }
        
        // é‡æ–°é…ç½®PhotoOutputä»¥ç¡®ä¿é«˜åˆ†è¾¨ç‡è®¾ç½®æ­£ç¡®
        if currentPhotoResolution == .resolution48MP {
            // 48MPæ¨¡å¼ï¼šç¡®ä¿PhotoOutputé…ç½®æ­£ç¡®
            photoOutput.isHighResolutionCaptureEnabled = true
            photoOutput.maxPhotoQualityPrioritization = .quality
            print("ğŸ”„ 48MPæ¨¡å¼ï¼šé‡æ–°é…ç½®PhotoOutput")
        }
        
        // æ ¹æ®åˆ†è¾¨ç‡é…ç½®ç›¸åº”çš„è®¾å¤‡æ ¼å¼
        if let device = currentDevice {
            if currentPhotoResolution == .resolution48MP {
                highResolutionManager.configureFor48MP(enable: true, device: device, session: session)
            } else {
                highResolutionManager.configureFor48MP(enable: false, device: device, session: session)
            }
        }
        
        session.commitConfiguration()
        
        print("ğŸ”„ Sessioné‡æ–°é…ç½®å®Œæˆ")
    }
    
    var is48MPAvailable: Bool {
        return highResolutionManager.is48MPAvailable(for: currentDevice)
    }
    
    // ğŸš€ ä¼˜åŒ–åçš„æ°´å°å’Œç›¸æ¡†åŠŸèƒ½ï¼šæ™ºèƒ½å¤„ç†é€»è¾‘
    private func applyWatermarkIfNeeded(to imageData: Data, photo: AVCapturePhoto) -> Data {
        print("ğŸ¨ å¼€å§‹åº”ç”¨æ°´å°å’Œç›¸æ¡†ï¼ŒåŸå§‹å¤§å°: \(imageData.count / 1024 / 1024)MB")
        
        var processedData = imageData
        let hasFrame = currentFrameSettings?.selectedFrame != .none
        let watermarkSettings = WatermarkSettings.load()
        let hasWatermark = watermarkSettings.isEnabled
        
        print("ğŸ¨ å¤„ç†çŠ¶æ€: ç›¸æ¡†=\(hasFrame), æ°´å°=\(hasWatermark)")
        
        if hasFrame {
            // æœ‰ç›¸æ¡†çš„æƒ…å†µï¼šå°†æ°´å°ä¿¡æ¯é›†æˆåˆ°ç›¸æ¡†ä¸­å¤„ç†
            if let frameSettings = currentFrameSettings {
                autoreleasepool {
                    print("ğŸ¨ åº”ç”¨ç›¸æ¡†å¹¶é›†æˆæ°´å°ä¿¡æ¯")
                    let photoDecorationService = PhotoDecorationService(frameSettings: frameSettings)
                    
                    // æå–ç›¸æœºè®¾ç½®ä¿¡æ¯ä¾›ç›¸æ¡†ä½¿ç”¨
                    let captureSettings = extractCaptureSettings(from: photo)
                    
                    // ğŸš€ ä¿®å¤ï¼šå¯¹äºéœ€è¦æ˜¾ç¤ºæ‹æ‘„å‚æ•°çš„ç›¸æ¡†ï¼ˆå¦‚å¤§å¸ˆç³»åˆ—ï¼‰ï¼Œå³ä½¿æ²¡æœ‰æ°´å°ä¹Ÿè¦ä¼ é€’captureSettings
                    let needsCaptureInfo = frameSettings.showISO || frameSettings.showAperture || 
                                         frameSettings.showFocalLength || frameSettings.showShutterSpeed
                    
                    print("ğŸ”§ ç›¸æ¡†å‚æ•°éœ€æ±‚æ£€æŸ¥:")
                    print("  - hasWatermark: \(hasWatermark)")
                    print("  - needsCaptureInfo: \(needsCaptureInfo)")
                    print("  - æœ€ç»ˆä¼ é€’captureSettings: \(hasWatermark || needsCaptureInfo)")
                    
                    processedData = photoDecorationService.applyFrameToPhoto(
                        processedData, 
                        withWatermarkInfo: (hasWatermark || needsCaptureInfo) ? captureSettings : nil,
                        aspectRatio: currentAspectRatio
                    )
                    print("ğŸ¨ ç›¸æ¡†+æ°´å°å¤„ç†å®Œæˆï¼Œå¤§å°: \(processedData.count / 1024 / 1024)MB")
                }
            }
        } else if hasWatermark {
            // æ²¡æœ‰ç›¸æ¡†ä½†æœ‰æ°´å°ï¼šä¿æŒåŸæœ‰é€»è¾‘ï¼Œå°†æ°´å°æ·»åŠ åˆ°ç…§ç‰‡ä¸Š
            autoreleasepool {
                print("ğŸ¨ åº”ç”¨æ°´å°åˆ°ç…§ç‰‡")
                let watermarkProcessor = WatermarkProcessor(currentDevice: currentDevice)
                processedData = watermarkProcessor.processWatermark(
                    imageData: processedData, 
                    photo: photo, 
                    format: currentPhotoFormat, 
                    aspectRatio: currentAspectRatio
                )
                print("ğŸ¨ æ°´å°å¤„ç†å®Œæˆï¼Œå¤§å°: \(processedData.count / 1024 / 1024)MB")
            }
        }
        
        return processedData
    }
    
    // æå–æ‹æ‘„è®¾ç½®ä¿¡æ¯çš„è¾…åŠ©æ–¹æ³•
    private func extractCaptureSettings(from photo: AVCapturePhoto) -> CameraCaptureSettings {
        // ä½¿ç”¨æ–°çš„é™æ€æ–¹æ³•åˆ›å»ºå¢å¼ºçš„ç›¸æœºè®¾ç½®
        return CameraCaptureSettings.fromPhoto(photo, device: currentDevice)
    }
}

extension CameraService: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            photoCompletionHandler?(.failure(error))
            return
        }
        
        // ğŸš€ å…³é”®ä¼˜åŒ–ï¼šç«‹å³è¿”å›æˆåŠŸï¼Œé‡Šæ”¾æ‹æ‘„çŠ¶æ€ï¼Œå…è®¸è¿ç»­æ‹æ‘„
        print("ğŸš€ æ‹æ‘„å®Œæˆï¼Œç«‹å³é‡Šæ”¾æ‹æ‘„çŠ¶æ€ï¼Œæ°´å°å°†åœ¨åå°å¤„ç†")
        
        // ä½¿ç”¨æœ€å°çš„æ•°æ®é‡è¿›è¡Œå¿«é€Ÿè¿”å›
        autoreleasepool {
            guard let imageData = photo.fileDataRepresentation() else {
                let error = NSError(domain: "CameraService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to get image data"])
                photoCompletionHandler?(.failure(error))
                return
            }
            
            // ç«‹å³è¿”å›æˆåŠŸçŠ¶æ€ï¼ˆä½¿ç”¨å°æ•°æ®é‡ï¼‰
            photoCompletionHandler?(.success(imageData))
            photoCompletionHandler = nil
            
            // ğŸš€ åœ¨ç‹¬ç«‹çš„åå°çº¿ç¨‹ä¸­å¤„ç†ï¼Œé¿å…å†…å­˜å³°å€¼é‡å 
            DispatchQueue.global(qos: .utility).async { [weak self] in
                self?.processPhotoInBackground(photo: photo, originalData: imageData)
            }
        }
    }
    
    // ğŸš€ æ–°å¢ï¼šç‹¬ç«‹çš„åå°å¤„ç†æ–¹æ³•ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
    private func processPhotoInBackground(photo: AVCapturePhoto, originalData: Data) {
        // ä½¿ç”¨æœ€å¤§çš„autoreleasepoolåŒ…å›´æ•´ä¸ªå¤„ç†è¿‡ç¨‹
        autoreleasepool {
            print("ğŸ¨ å¼€å§‹åå°å¤„ç† - å½“å‰å†…å­˜å‹åŠ›è¾ƒä½çš„çº¿ç¨‹")
            
            // æå–æ‹æ‘„è®¾ç½®ä¿¡æ¯
            let captureSettings = self.extractCaptureSettings(from: photo)
            let dataSize = originalData.count / (1024 * 1024)
            print("ğŸ“Š åŸå§‹æ•°æ®å¤§å°: \(dataSize)MB")
            
            // å…ˆéªŒè¯å›¾åƒï¼ˆå‡å°‘å†…å­˜å ç”¨ç‰ˆæœ¬ï¼‰
            print("ğŸ“Š æ­¥éª¤1: éªŒè¯å›¾åƒ")
            self.verifyImageDataLightweight(originalData)
            
            // åˆ†æ­¥å¤„ç†ï¼Œæ¯ä¸€æ­¥éƒ½ç”¨autoreleasepool
            let finalImageData: Data
            
            // ç¬¬ä¸€æ­¥ï¼šåº”ç”¨æ°´å°å’Œç›¸æ¡†
            finalImageData = autoreleasepool {
                print("ğŸ“Š æ­¥éª¤2: åº”ç”¨æ°´å°å’Œç›¸æ¡†")
                let processedData = self.applyWatermarkIfNeeded(to: originalData, photo: photo)
                let processedSize = processedData.count / (1024 * 1024)
                print("ğŸ“Š æ°´å°å¤„ç†å®Œæˆï¼Œå¤§å°: \(processedSize)MB")
                return processedData
            }
            
            // ç¬¬äºŒæ­¥ï¼šä¿å­˜åˆ°ç›¸å†Œ
            autoreleasepool {
                print("ğŸ“Š æ­¥éª¤3: ä¿å­˜åˆ°ç›¸å†Œ")
                self.photoProcessor.savePhotoToLibrary(
                    finalImageData,
                    format: self.currentPhotoFormat,
                    aspectRatio: self.currentAspectRatio,
                    frameSettings: self.currentFrameSettings,
                    captureSettings: captureSettings
                )
                print("âœ… ä¿å­˜å®Œæˆ")
            }
            
            print("âœ… åå°å¤„ç†å®Œæˆï¼šæ°´å° + ç›¸æ¡† + ä¿å­˜")
            
            // ğŸš€ é€šçŸ¥ä¸»çº¿ç¨‹å¤„ç†å®Œæˆ
            DispatchQueue.main.async { [weak self] in
                // é€šçŸ¥ViewModelå¤„ç†å®Œæˆï¼ˆå¦‚æœéœ€è¦ï¼‰
                NotificationCenter.default.post(name: NSNotification.Name("BackgroundProcessingCompleted"), object: nil)
            }
        }
    }
    
    // ğŸš€ æ–°å¢ï¼šè½»é‡çº§å›¾åƒéªŒè¯ï¼Œå‡å°‘å†…å­˜å ç”¨
    private func verifyImageDataLightweight(_ imageData: Data) {
        autoreleasepool {
            // åªè·å–åŸºæœ¬çš„å›¾åƒå±æ€§ï¼Œä¸åˆ›å»ºå®Œæ•´çš„å›¾åƒå¯¹è±¡
            guard let source = CGImageSourceCreateWithData(imageData as CFData, nil) else { 
                print("âŒ æ— æ³•åˆ›å»ºå›¾åƒæº")
                return 
            }
            
            // åªè·å–å›¾åƒå±æ€§ï¼Œä¸åŠ è½½å›¾åƒæ•°æ®
            guard let properties = CGImageSourceCopyPropertiesAtIndex(source, 0, nil) as? [String: Any] else {
                print("âŒ æ— æ³•è·å–å›¾åƒå±æ€§")
                return
            }
            
            if let pixelWidth = properties[kCGImagePropertyPixelWidth as String] as? Int,
               let pixelHeight = properties[kCGImagePropertyPixelHeight as String] as? Int {
                let megapixels = (pixelWidth * pixelHeight) / 1_000_000
                let dataSize = imageData.count / (1024 * 1024) // MB
                
                print("ğŸ” å›¾åƒä¿¡æ¯: \(pixelWidth)x\(pixelHeight) (\(megapixels)MP), å¤§å°: \(dataSize)MB")
                
                if currentPhotoResolution == .resolution48MP && megapixels < 40 {
                    print("âŒ è­¦å‘Šï¼šé¢„æœŸ48MPä½†å®é™…æ‹æ‘„\(megapixels)MP")
                } else if currentPhotoResolution == .resolution48MP && megapixels >= 40 {
                    print("âœ… æˆåŠŸï¼š48MPæ¨¡å¼")
                }
            }
        }
    }
    
    private func verifyImageData(_ imageData: Data) {
        // ä¿ç•™åŸæ–¹æ³•ç”¨äºå…¼å®¹ï¼Œä½†æ ‡è®°ä¸ºå·²å¼ƒç”¨
        verifyImageDataLightweight(imageData)
    }
}